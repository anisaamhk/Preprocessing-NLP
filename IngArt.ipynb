{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #import library nltk\n",
    "from nltk.tokenize import word_tokenize #import word_tokenize for tokenizing text into words \n",
    "from nltk.tokenize import sent_tokenize #import sent_tokenize for tokenizing paragraph into sentences\n",
    "from nltk.stem.porter import PorterStemmer #import Porter Stemmer Algorithm \n",
    "from nltk.stem import WordNetLemmatizer #import WordNet lemmatizer \n",
    "from nltk.corpus import stopwords #import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory #import Indonesian Stemmer\n",
    "import re #import regular expression\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenization(s): \n",
    "    sentences_list = sent_tokenize(s)\n",
    "    return sentences_list \n",
    "\n",
    "#remove punctuation from string\n",
    "def removeDigit(str):\n",
    "    new_string =  re.sub(r\"[\\W]\", \" \", str)\n",
    "    return new_string\n",
    "\n",
    "#casefolding\n",
    "def casefolding(s):\n",
    "    new_str = s.lower()\n",
    "    \n",
    "    return new_str\n",
    "\n",
    "#Stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def stpword(str):\n",
    "    word_tokens = word_tokenize(str) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
    "    filtered_sentence = [] \n",
    "    \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "#Stemming English\n",
    "def stemmingEnglish(str):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    words = word_tokenize(str)\n",
    "    result = list()\n",
    "    for word in words:\n",
    "        result.append(porter_stemmer.stem(word))\n",
    "        \n",
    "    return ' '.join(result)\n",
    "\n",
    "#pos tagging\n",
    "def postag(str):\n",
    "    tok_sentence = nltk.word_tokenize(str)\n",
    "    tagged_sentence = nltk.pos_tag(tok_sentence)\n",
    "    return tagged_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 'NN'), ('peopl', 'NN'), ('order', 'NN'), ('new', 'JJ'), ('period', 'NN'), ('presum', 'NN'), ('greater', 'JJR'), ('younger', 'JJR'), ('degre', 'NN'), ('xer', 'NNP'), ('percent', 'NN'), ('america', 'NN'), ('yet', 'RB'), ('thank', 'JJ'), ('coupl', 'NN'), ('professor', 'NN'), ('millenni', 'NN'), ('compar', 'NN'), ('stabl', 'NNS'), ('say', 'VBP'), ('children', 'NNS'), ('anoth', 'DT'), ('crunch', 'NN'), ('found', 'VBD'), ('philip', 'RB'), ('marri', 'JJ'), ('2016', 'CD'), ('studi', 'NN'), ('today', 'NN'), ('knot', 'VBP'), ('us', 'PRP'), ('get', 'VB'), ('2008', 'CD'), ('tradit', 'NN'), ('bureau', 'NN'), ('wed', 'VBD'), ('35', 'CD'), ('older', 'JJR'), ('american', 'JJ'), ('research', 'NN'), ('divorc', 'NN'), ('censu', 'JJ'), ('year', 'NN'), ('rate', 'NN'), ('respons', 'NNS'), ('old', 'JJ'), ('factor', 'NN'), ('univers', 'NNS'), ('cohen', 'VBP'), ('gen', 'NN'), ('divorc', 'NN'), ('get', 'VBP'), ('anniversari', 'JJ'), ('drop', 'NN'), ('appl', 'NN'), ('marriag', 'NN'), ('later', 'RB'), ('millenni', 'RB'), ('less', 'RBR'), ('hit', 'JJ'), ('maryland', 'NN'), ('data', 'NNS'), ('discov', 'RB'), ('live', 'VBP'), ('risk', 'NN'), ('18', 'CD'), ('tie', 'NN'), ('alreadi', 'NN'), ('shirk', 'NN'), ('said', 'VBD'), ('see', 'JJ'), ('shrink', 'JJ'), ('matur', 'NN'), ('fifth', 'JJ'), ('colleg', 'NN'), ('like', 'IN')]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file = open('Kakich.txt', 'r')\n",
    "    text_data = file.read()\n",
    "    rm = removeDigit(text_data)\n",
    "    cs = casefolding(rm)\n",
    "    stop = stpword(cs)\n",
    "    list1 = list(set(stop))\n",
    "    str1 = ' '.join(list1)\n",
    "    st = stemmingEnglish(str1) \n",
    "    post = postag(st)\n",
    "    print(post)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
